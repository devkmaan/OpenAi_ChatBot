{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "bca81529",
      "metadata": {
        "id": "bca81529"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"test.csv\", encoding='unicode_escape')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "81ddbe6f",
      "metadata": {
        "id": "81ddbe6f"
      },
      "outputs": [],
      "source": [
        "questions_list = df['Questions'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "94b1baae",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Hi',\n",
              " 'Hola',\n",
              " 'Good Morning',\n",
              " 'Fine',\n",
              " 'I am good',\n",
              " 'How are you?',\n",
              " 'Hey',\n",
              " 'What are your interests?',\n",
              " 'What is your number?',\n",
              " 'What is your favorite number?',\n",
              " 'What can you eat?',\n",
              " \"Why can't you eat food?\",\n",
              " 'What is your location?',\n",
              " 'What is your location?',\n",
              " 'Where are you from?',\n",
              " 'Where are you?',\n",
              " 'Do you have any brothers?',\n",
              " 'Do you have any brothers?',\n",
              " 'Who is your father?',\n",
              " 'Who is your mother?',\n",
              " 'Who is your boss?',\n",
              " 'What is your age?',\n",
              " 'What is your age?',\n",
              " 'what is the illuminati?',\n",
              " 'what is the illuminatti?',\n",
              " 'what is vineland?',\n",
              " 'What is Illuminatus?',\n",
              " 'who wrote vineland',\n",
              " 'who is bilbo baggins?',\n",
              " 'who is geoffrey chaucer',\n",
              " 'who is piers anthony?',\n",
              " 'have you read plato?',\n",
              " 'have you read frankenstein',\n",
              " 'have you ever read a book?',\n",
              " 'have you read homer?',\n",
              " 'what are you doing?',\n",
              " 'Tell me a joke',\n",
              " 'where is the cdac located',\n",
              " 'college is located at',\n",
              " 'where is cdac',\n",
              " 'where is college located',\n",
              " 'address of college',\n",
              " 'how to reach cdac',\n",
              " 'cdac location',\n",
              " 'cdac address',\n",
              " 'wheres the cdac',\n",
              " 'whats is the cdac address',\n",
              " 'what is the address of cdac',\n",
              " 'address',\n",
              " 'location',\n",
              " 'information about fee',\n",
              " 'information on fee',\n",
              " 'tell me the fee',\n",
              " 'what is fee',\n",
              " 'fees',\n",
              " 'fee',\n",
              " 'do you have hostel',\n",
              " 'do you guys have hostel',\n",
              " 'is there hostel facility available',\n",
              " 'Hostel',\n",
              " 'Stay',\n",
              " 'hostel capacity',\n",
              " 'hostel intake',\n",
              " 'what is the hostel fee',\n",
              " 'total fees charged by the hostel',\n",
              " 'hostel fees',\n",
              " 'hostel charges',\n",
              " 'where is the hostel',\n",
              " 'where hostel is located ',\n",
              " 'what is the hostel address',\n",
              " 'how to get in hostel',\n",
              " 'how to opt for hostel',\n",
              " 'where should is apply for hostel',\n",
              " 'hostel booking',\n",
              " 'booking hostel',\n",
              " 'hostel college distance',\n",
              " 'college to hostel distance',\n",
              " 'distance between college and hostel',\n",
              " 'distance between hostel and college',\n",
              " 'how big is the hostel',\n",
              " 'hostel size',\n",
              " 'hostel facilities',\n",
              " 'hostel address',\n",
              " 'cdac address',\n",
              " 'hostel location',\n",
              " 'hostel address',\n",
              " 'cdac locations',\n",
              " 'Who is managing hostel facilities ',\n",
              " 'To whom should I complain regarding hostel facilities ',\n",
              " 'who is Hostel coordinator',\n",
              " 'Warden',\n",
              " 'Hostel warden',\n",
              " 'document to bring',\n",
              " 'documents needed for admision',\n",
              " 'documents needed at the time of admission',\n",
              " 'documents needed during admission',\n",
              " 'documents required for admision',\n",
              " 'documents required at the time of admission',\n",
              " 'documents required during admission',\n",
              " 'What document are required for admission',\n",
              " 'Which document to bring for admission',\n",
              " 'documents',\n",
              " 'what documents do i need',\n",
              " 'what documents do I need for admission',\n",
              " 'documents needed',\n",
              " 'how many classroom do you have ',\n",
              " 'Could you please tell me the number of classrooms at your institution ',\n",
              " 'How many classrooms does your institution have',\n",
              " 'number of classroom ',\n",
              " 'classroom ',\n",
              " 'labs ',\n",
              " 'number of labs',\n",
              " 'how many number of lab do you have ',\n",
              " 'building structure',\n",
              " 'size of campus',\n",
              " 'building size',\n",
              " 'How many floors does college have',\n",
              " 'floors in college',\n",
              " \"how tall is CDAC's  college building\",\n",
              " 'floors',\n",
              " 'is there any library',\n",
              " 'library facility',\n",
              " 'library facilities',\n",
              " 'do you have library',\n",
              " 'does the college have library facility',\n",
              " 'college library',\n",
              " 'where can i get books',\n",
              " 'book facility',\n",
              " 'Where is library',\n",
              " 'Library',\n",
              " 'Library information',\n",
              " 'Library books information',\n",
              " 'Tell me about library',\n",
              " 'how many libraries',\n",
              " 'food facilities',\n",
              " 'canteen facilities',\n",
              " 'canteen facility',\n",
              " 'is there any canteen',\n",
              " 'Is there a cafetaria in college',\n",
              " 'Does college have canteen',\n",
              " 'Where is canteen',\n",
              " 'where is cafetaria',\n",
              " 'canteen',\n",
              " 'Food',\n",
              " 'Cafetaria\"We have dining for hostelers and for day scholars they have buy coupon from the reception',\n",
              " 'food menu',\n",
              " 'food in canteen',\n",
              " 'Whats there on menu',\n",
              " 'what is available in college canteen',\n",
              " 'what foods can we get in college canteen',\n",
              " 'food variety',\n",
              " 'What is there to eat?',\n",
              " 'Could you please tell me who the current placement coordinator is ',\n",
              " 'Who handles placement inquiries at this institution ',\n",
              " 'Whom should I contact regarding placement opportunities',\n",
              " 'what is the process of admission',\n",
              " 'what is the admission process',\n",
              " 'How to take admission in your college',\n",
              " 'What is the process for admission',\n",
              " 'admission',\n",
              " 'admission process',\n",
              " 'What facilities cdac provide',\n",
              " 'cdac facility',\n",
              " 'What are cdac facilities',\n",
              " 'facilities provided by cdac',\n",
              " 'max number of students',\n",
              " 'number of seats per branch',\n",
              " 'number of seats in each branch',\n",
              " 'maximum number of seats',\n",
              " 'maximum students intake',\n",
              " 'What is college intake',\n",
              " 'how many stundent are taken in each branch',\n",
              " 'seat allotment',\n",
              " 'seats',\n",
              " 'cdac dress code',\n",
              " 'cdac dresscode',\n",
              " 'can we wear casuals',\n",
              " 'Does cdac have an uniforn',\n",
              " 'do we have to wear form',\n",
              " 'can we casuals ?',\n",
              " 'is there we have wear formals ?',\n",
              " 'does formal is compulsary ?',\n",
              " 'when we have wear a formals ?',\n",
              " 'what are the different committe in college',\n",
              " 'different committee in college',\n",
              " 'Are there any committee in college',\n",
              " 'Give me committee details',\n",
              " 'committee',\n",
              " 'how many committee are there in college',\n",
              " 'What languages are permitted for spoken communication on campus ? ',\n",
              " 'Which languages are officially recognized for spoken communication on campus ?',\n",
              " 'What languages are okay to speak on campus ?',\n",
              " 'What languages can you chat in on campus ?',\n",
              " 'holidays in cdac',\n",
              " 'when will course starts',\n",
              " 'when will course end',\n",
              " 'when is the holidays',\n",
              " 'list of holidays',\n",
              " 'Holiday in these year',\n",
              " 'holiday list',\n",
              " 'about vacations',\n",
              " 'about holidays',\n",
              " 'When is vacation',\n",
              " 'When is holidays',\n",
              " 'sports and games',\n",
              " 'give sports details',\n",
              " 'sports infrastructure',\n",
              " 'sports facilities',\n",
              " 'information about sports',\n",
              " 'Sports activities',\n",
              " 'please provide sports and games information',\n",
              " 'what can you do',\n",
              " 'what are the thing you can do',\n",
              " 'things you can do',\n",
              " 'what can u do for me',\n",
              " 'how u can help me',\n",
              " 'why i should use you',\n",
              " 'help',\n",
              " 'can you help me',\n",
              " 'how long will be the vacation',\n",
              " 'What are your interests?',\n",
              " 'What are your favorite subjects?',\n",
              " 'What is cdac?',\n",
              " 'What is full form of cdac?',\n",
              " 'When was cdac developed?',\n",
              " 'What is GIST and NCST?',\n",
              " 'What is R&D?']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "64601d5e",
      "metadata": {
        "id": "64601d5e"
      },
      "outputs": [],
      "source": [
        "answers_list = df['Answers'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a3bffd3a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3bffd3a",
        "outputId": "2836429f-1ca8-41ea-cba0-0f93ac545368"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\aquib\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\aquib\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\aquib\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5e900a08",
      "metadata": {
        "id": "5e900a08"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "def preprocess(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stemmer = PorterStemmer()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove non-alphanumeric characters\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
        "    return ' '.join(stemmed_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "194886bb",
      "metadata": {
        "id": "194886bb"
      },
      "outputs": [],
      "source": [
        "def preprocess_with_stopwords(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stemmer = PorterStemmer()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove non-alphanumeric characters\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
        "    return ' '.join(stemmed_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d4d658f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4d658f6",
        "outputId": "6292ea33-aa38-462a-9a4b-f4e19ef42135"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\aquib\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
        "X = vectorizer.fit_transform([preprocess(q) for q in questions_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a0320d12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "a0320d12",
        "outputId": "13ba0331-5492-4b86-ea40-74bcb93ed502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed_text: who is m dhoni\n",
            "similarities: [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "max_similarity: 0.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"I can't answer this question.\""
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
        "X = vectorizer.fit_transform([preprocess(q) for q in questions_list])\n",
        "\n",
        "def get_response(text):\n",
        "    processed_text = preprocess_with_stopwords(text)\n",
        "    print(\"processed_text:\", processed_text)\n",
        "    vectorized_text = vectorizer.transform([processed_text])\n",
        "    similarities = cosine_similarity(vectorized_text, X)\n",
        "    print(\"similarities:\", similarities)\n",
        "    max_similarity = np.max(similarities)\n",
        "    print(\"max_similarity:\", max_similarity)\n",
        "    if max_similarity > 0.6:\n",
        "        high_similarity_questions = [q for q, s in zip(questions_list, similarities[0]) if s > 0.6]\n",
        "        print(\"high_similarity_questions:\", high_similarity_questions)\n",
        "\n",
        "        target_answers = []\n",
        "        for q in high_similarity_questions:\n",
        "            q_index = questions_list.index(q)\n",
        "            target_answers.append(answers_list[q_index])\n",
        "        print(target_answers)\n",
        "\n",
        "        Z = vectorizer.fit_transform([preprocess_with_stopwords(q) for q in high_similarity_questions])\n",
        "        processed_text_with_stopwords = preprocess_with_stopwords(text)\n",
        "        print(\"processed_text_with_stopwords:\", processed_text_with_stopwords)\n",
        "        vectorized_text_with_stopwords = vectorizer.transform([processed_text_with_stopwords])\n",
        "        final_similarities = cosine_similarity(vectorized_text_with_stopwords, Z)\n",
        "        closest = np.argmax(final_similarities)\n",
        "        return target_answers[closest]\n",
        "    else:\n",
        "        return \"I can't answer this question.\"\n",
        "\n",
        "get_response('Who is ms dhoni?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "NUoJPaJUX9co",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "NUoJPaJUX9co",
        "outputId": "665663eb-e438-446f-c343-909d76721f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processed_text: what is machin learn\n",
            "similarities: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.71047193 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.70710678 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.        ]]\n",
            "max_similarity: 0.7104719326300846\n",
            "high_similarity_questions: ['whats is the cdac address', 'Whats there on menu']\n",
            "['The Bengaluru CDAC Center is located at No. 68, 4th Cross, Electronic City Phase 1, Hosur Road, Bengaluru, Karnataka 560100. You can use this address to reach our center, located opposite the BSNL Telephone Exchange. ', 'we serve Idli,Poha, Chole-Bhature, Alu-parathe, Alu-puri, Veg-Thali, Sandwich, Samosa, Sweets,Chai, Coffee etc']\n",
            "processed_text_with_stopwords: what is machin learn\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The Bengaluru CDAC Center is located at No. 68, 4th Cross, Electronic City Phase 1, Hosur Road, Bengaluru, Karnataka 560100. You can use this address to reach our center, located opposite the BSNL Telephone Exchange. '"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
        "X = vectorizer.fit_transform([preprocess(q) for q in questions_list])\n",
        "\n",
        "def get_response(text):\n",
        "    processed_text = preprocess_with_stopwords(text)\n",
        "    print(\"processed_text:\", processed_text)\n",
        "    vectorized_text = vectorizer.transform([processed_text])\n",
        "    similarities = cosine_similarity(vectorized_text, X)\n",
        "    print(\"similarities:\", similarities)\n",
        "    max_similarity = np.max(similarities)\n",
        "    print(\"max_similarity:\", max_similarity)\n",
        "    if max_similarity > 0.6:\n",
        "        high_similarity_questions = [q for q, s in zip(questions_list, similarities[0]) if s > 0.6]\n",
        "        print(\"high_similarity_questions:\", high_similarity_questions)\n",
        "\n",
        "        target_answers = []\n",
        "        for q in high_similarity_questions:\n",
        "            q_index = questions_list.index(q)\n",
        "            target_answers.append(answers_list[q_index])\n",
        "        print(target_answers)\n",
        "\n",
        "        Z = vectorizer.fit_transform([preprocess_with_stopwords(q) for q in high_similarity_questions])\n",
        "        processed_text_with_stopwords = preprocess_with_stopwords(text)\n",
        "        print(\"processed_text_with_stopwords:\", processed_text_with_stopwords)\n",
        "        vectorized_text_with_stopwords = vectorizer.transform([processed_text_with_stopwords])\n",
        "        final_similarities = cosine_similarity(vectorized_text_with_stopwords, Z)\n",
        "        closest = np.argmax(final_similarities)\n",
        "        return target_answers[closest]\n",
        "    else:\n",
        "        return \"I can't answer this question.\"\n",
        "\n",
        "get_response('what is machine learning')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "uJ_s0VrsjGcs",
      "metadata": {
        "id": "uJ_s0VrsjGcs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspellchecker in c:\\users\\aquib\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.8.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pyspellchecker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93c792f2",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb9cd2ae",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
